{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07dc97a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69d74504",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_DIM = 74\n",
    "LATENT_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db60f2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        \n",
    "        self.features = self.data_frame.drop(columns=[\"Label\"])\n",
    "        self.features = self.features.select_dtypes(include=[np.number])\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        features = self.features.iloc[idx].values.astype(np.float32)\n",
    "        return torch.tensor(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34aa3a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(LATENT_DIM, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, FEATURE_DIM),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, z):\n",
    "        return self.model(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c58ac1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Critic, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(FEATURE_DIM, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad5dfbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5efdf3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_critic = 5\n",
    "clip_value = 0.01\n",
    "batch_size = 64\n",
    "steps = 1e5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "760c2210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on ./data/FTP-Patator.csv: 6878 samples\n",
      "Epoch [925/926] Batch 108/108                 Loss D: -118911624.0000, Loss G: -0.1621\n",
      "Training on ./data/PortScan.csv: 20000 samples\n",
      "Epoch [319/320] Batch 313/313                 Loss D: -103156016.0000, Loss G: -0.1151\n",
      "Training on ./data/Web Attack Brute Force.csv: 1507 samples\n",
      "Epoch [4166/4167] Batch 24/24                 Loss D: -122802632.0000, Loss G: -0.1978\n",
      "Training on ./data/Web Attack XSS.csv: 652 samples\n",
      "Epoch [9090/9091] Batch 11/11                 Loss D: -121820224.0000, Loss G: -0.1703\n",
      "Training on ./data/BENIGN.csv: 20000 samples\n",
      "Epoch [319/320] Batch 313/313                 Loss D: -2.5565, Loss G: -0.02307\n",
      "Training on ./data/Web_Attack_Sql_Injection.csv: 21 samples\n",
      "Epoch [100000/100001] Batch 1/1                 Loss D: -115448440.0000, Loss G: -0.1656\n",
      "Training on ./data/Web_Attack_XSS.csv: 652 samples\n",
      "Epoch [9090/9091] Batch 11/11                 Loss D: -109647872.0000, Loss G: -0.2135\n",
      "Training on ./data/DoS Slowhttptest.csv: 5263 samples\n",
      "Epoch [1204/1205] Batch 83/83                 Loss D: -109315824.0000, Loss G: -0.1158\n",
      "Training on ./data/DoS_GoldenEye.csv: 10286 samples\n",
      "Epoch [621/622] Batch 161/161                 Loss D: -142199056.0000, Loss G: -0.1445\n",
      "Training on ./data/Web_Attack_Brute_Force.csv: 1507 samples\n",
      "Epoch [4166/4167] Batch 24/24                 Loss D: -124852168.0000, Loss G: -0.2039\n",
      "Training on ./data/DoS Hulk.csv: 20000 samples\n",
      "Epoch [319/320] Batch 313/313                 Loss D: -126595840.0000, Loss G: -0.1710\n",
      "Training on ./data/Heartbleed.csv: 11 samples\n",
      "Epoch [100000/100001] Batch 1/1                 Loss D: -111534744.0000, Loss G: -0.1525\n",
      "Training on ./data/DoS slowloris.csv: 5692 samples\n",
      "Epoch [1123/1124] Batch 89/89                 Loss D: -115687968.0000, Loss G: -0.1529\n",
      "Training on ./data/Bot.csv: 1954 samples\n",
      "Epoch [3225/3226] Batch 31/31                 Loss D: -415.5315, Loss G: -0.0790\n",
      "Training on ./data/Infiltration.csv: 36 samples\n",
      "Epoch [100000/100001] Batch 1/1                 Loss D: -137048768.0000, Loss G: -0.1280\n",
      "Training on ./data/DoS GoldenEye.csv: 10286 samples\n",
      "Epoch [621/622] Batch 161/161                 Loss D: -117433800.0000, Loss G: -0.0843\n",
      "Training on ./data/Web Attack Sql Injection.csv: 21 samples\n",
      "Epoch [100000/100001] Batch 1/1                 Loss D: -111592304.0000, Loss G: -0.1674\n",
      "Training on ./data/DoS_Slowhttptest.csv: 5263 samples\n",
      "Epoch [1204/1205] Batch 83/83                 Loss D: -143043744.0000, Loss G: -0.1593\n",
      "Training on ./data/SSH-Patator.csv: 5098 samples\n",
      "Epoch [1250/1251] Batch 80/80                 Loss D: -110167488.0000, Loss G: -0.1419\n",
      "Training on ./data/DoS_Hulk.csv: 20000 samples\n",
      "Epoch [319/320] Batch 313/313                 Loss D: -111009744.0000, Loss G: -0.1147\n",
      "Training on ./data/DDoS.csv: 20000 samples\n",
      "Epoch [319/320] Batch 313/313                 Loss D: -4.1427, Loss G: -0.1853\n",
      "Training on ./data/DoS_slowloris.csv: 5692 samples\n",
      "Epoch [1123/1124] Batch 89/89                 Loss D: -134701440.0000, Loss G: -0.1479\n",
      "\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "files = glob(\"./data/*.csv\")\n",
    "\n",
    "for file in files:\n",
    "    basename = os.path.basename(file)\n",
    "    basename = basename.replace(\".csv\", \"\").replace(\" \", \"_\")\n",
    "\n",
    "    dataset = FlowDataset(file)\n",
    "    print(f\"Training on {file}: {len(dataset)} samples\")\n",
    "    dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    generator = Generator().to(device)\n",
    "    critic = Critic().to(device)\n",
    "    critic_optimizer = optim.RMSprop(critic.parameters(), lr=learning_rate)\n",
    "    generator_optimizer = optim.RMSprop(generator.parameters(), lr=learning_rate)\n",
    "\n",
    "    epochs = int(steps / len(dataloader)) + 1\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for i, real_data in enumerate(dataloader):\n",
    "            real_data = real_data.to(device)\n",
    "            batch_size = real_data.size(0)\n",
    "\n",
    "            critic_optimizer.zero_grad()\n",
    "\n",
    "            critic_real = critic(real_data)\n",
    "\n",
    "            z = torch.randn(batch_size, LATENT_DIM, device=device)\n",
    "            fake_data = generator(z).detach()\n",
    "            critic_fake = critic(fake_data)\n",
    "\n",
    "            critic_loss = -(torch.mean(critic_real) - torch.mean(critic_fake))\n",
    "            critic_loss.backward()\n",
    "            critic_optimizer.step()\n",
    "\n",
    "            for p in critic.parameters():\n",
    "                p.data.clamp_(-clip_value, clip_value)\n",
    "            \n",
    "            if i % n_critic == 0:\n",
    "                generator_optimizer.zero_grad()\n",
    "\n",
    "                z = torch.randn(batch_size, LATENT_DIM, device=device)\n",
    "                fake_data = generator(z)\n",
    "                critic_fake = critic(fake_data)\n",
    "\n",
    "                generator_loss = -torch.mean(critic_fake)\n",
    "                generator_loss.backward()\n",
    "                generator_optimizer.step()\n",
    "        else:\n",
    "            print(f\"\\rEpoch [{epoch:3d}/{epochs}] Batch {i+1}/{len(dataloader)} \\\n",
    "                Loss D: {critic_loss.item():.4f}, Loss G: {generator_loss.item():.4f}\", end=\"\")\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            with torch.no_grad():\n",
    "                z = torch.randn(64, LATENT_DIM, device=device)\n",
    "                fake_data = generator(z).cpu().numpy()\n",
    "                fake_data = pd.DataFrame(fake_data, columns=dataset.features.columns)\n",
    "                fake_data.to_csv(f\"./fake/fake_data_epoch_{epoch}.csv\")\n",
    "    else:\n",
    "        torch.save({\n",
    "            'generator_state_dict': generator.state_dict(),\n",
    "            'critic_state_dict': critic.state_dict(),\n",
    "            'generator_optimizer_state_dict': generator_optimizer.state_dict(),\n",
    "            'critic_optimizer_state_dict': critic_optimizer.state_dict(),\n",
    "        }, f'wgan_cicflowmeter_{basename}.pth')\n",
    "        print()\n",
    "\n",
    "print(\"\\nTraining complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fea37ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_data(generator, latent_dim, num_samples=1000):\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(num_samples, latent_dim).to(device)\n",
    "        fake_data = generator(z).cpu().numpy()\n",
    "        fake_data = pd.DataFrame(fake_data, columns=dataset.features.columns)\n",
    "    return fake_data\n",
    "\n",
    "generated_samples = generate_fake_data(generator, LATENT_DIM, num_samples=1000)\n",
    "\n",
    "def denormalize(data, min_values, max_values):\n",
    "    # Assuming the original data is in the range [0, 1]\n",
    "    # Adjust this function based on the original data's range\n",
    "    return data * (max_values - min_values) + min_values\n",
    "\n",
    "min_values = dataset.features.min().values\n",
    "max_values = dataset.features.max().values\n",
    "\n",
    "denormalize_data = denormalize(generated_samples, min_values, max_values)\n",
    "\n",
    "denormalize_data.to_csv(\"./denormalized_fake_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f27540c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'generator_state_dict': generator.state_dict(),\n",
    "    'critic_state_dict': critic.state_dict(),\n",
    "    'generator_optimizer_state_dict': generator_optimizer.state_dict(),\n",
    "    'critic_optimizer_state_dict': critic_optimizer.state_dict(),\n",
    "}, 'wgan_cicflow_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67a7620",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
