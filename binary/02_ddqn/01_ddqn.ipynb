{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow_package import data_preprocessing\n",
    "from flow_package.binary_flow_env import BinaryFlowEnv, InputType\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "TRAIN_PATH = os.path.abspath(\"../../dataset/cicids2017/train.csv\")\n",
    "TEST_PATH = os.path.abspath(\"../../dataset/cicids2017/test.csv\")\n",
    "\n",
    "train_data = pd.read_csv(TRAIN_PATH)\n",
    "test_data = pd.read_csv(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = InputType(\n",
    "    input_features=train_data.drop(columns=[\"Number Label\"]),\n",
    "    input_labels=train_data[\"Number Label\"],\n",
    "    reward_list=[1.0, -1.0]\n",
    ")\n",
    "train_env = BinaryFlowEnv(train_input)\n",
    "\n",
    "test_input = InputType(\n",
    "    input_features=test_data.drop(columns=[\"Number Label\"]),\n",
    "    input_labels=test_data[\"Number Label\"],\n",
    "    reward_list=[1.0, -1.0]\n",
    ")\n",
    "test_env = BinaryFlowEnv(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import random\n",
    "\n",
    "from collections import deque, namedtuple\n",
    "from itertools import count\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils as utils\n",
    "import torch.optim as optim\n",
    "\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "device_name = \"cpu\"\n",
    "\n",
    "if False:\n",
    "    if torch.cuda.is_available():\n",
    "        device_name = \"cuda\"\n",
    "    elif torch.mps.is_available():\n",
    "        device_name = \"mps\"\n",
    "    # elif torch.hip.is_available():\n",
    "    #     device_name = \"hip\"\n",
    "    elif torch.mtia.is_available():\n",
    "        device_name = \"mtia\"\n",
    "    elif torch.xpu.is_available():\n",
    "        device_name = \"xpu\"\n",
    "\n",
    "device = torch.device(device_name)\n",
    "print(f\"device: {device_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transaction = namedtuple('Transaction', ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        # self.capacity = capacity\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        self.memory.append(Transaction(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(data: list, show_result=False):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    # durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "\n",
    "    if show_result:\n",
    "        plt.title(\"Result\")\n",
    "    else:\n",
    "        plt.clf()\n",
    "        plt.title(\"Training...\")\n",
    "    means = [data[0]]\n",
    "    for i in range(1, len(data)):\n",
    "        means.append(np.mean(data[0:i]))\n",
    "\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"ratio\")\n",
    "    # plt.plot(data)\n",
    "    plt.plot(means, color=\"red\")\n",
    "    plt.grid()\n",
    "\n",
    "    plt.pause(0.001)\n",
    "    if is_ipython:\n",
    "        if not show_result:\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        else:\n",
    "            display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(metrics_dict: dict, show_result=False):\n",
    "    fig = plt.figure(figsize=(16, 20))\n",
    "\n",
    "    ac = fig.add_subplot(5, 1, 1)\n",
    "    ac.plot(metrics_dict[\"accuracy\"], label=\"accuracy\")\n",
    "    ac.grid()\n",
    "    ac.set_title(\"Accuracy\")\n",
    "\n",
    "    pr = fig.add_subplot(5, 1, 2)\n",
    "    pr.plot(metrics_dict[\"precision\"], label=\"precision\", color=\"green\")\n",
    "    pr.grid()\n",
    "    pr.set_title(\"Precision\")\n",
    "\n",
    "    re = fig.add_subplot(5, 1, 3)\n",
    "    re.plot(metrics_dict[\"recall\"], label=\"recall\", color=\"red\")\n",
    "    re.grid()\n",
    "    re.set_title(\"Recall\")\n",
    "\n",
    "    f1 = fig.add_subplot(5, 1, 4)\n",
    "    f1.plot(metrics_dict[\"f1\"], label=\"f1\", color=\"black\")\n",
    "    f1.grid()\n",
    "    f1.set_title(\"F1\")\n",
    "\n",
    "    fpr = fig.add_subplot(5, 1, 5)\n",
    "    fpr.plot(metrics_dict[\"fpr\"], label=\"fpr\", color=\"purple\")\n",
    "    fpr.grid()\n",
    "    fpr.set_title(\"FPR\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.pause(0.001)\n",
    "    if is_ipython:\n",
    "        if not show_result:\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        else:\n",
    "            display.display(plt.gcf())\n",
    "\n",
    "\n",
    "def calculate_metrics(tp, tn, fp, fn):\n",
    "    accuracy = (tp + tn) / (tp + fp + fn + tn)\n",
    "    precision = tp / (tp + fp) if tp + fp != 0 else -1\n",
    "    recall = tp / (tp + fn) if tp + fn != 0 else -1\n",
    "    f1 = 2 * precision * recall / (precision + recall) if precision + recall != 0 else None\n",
    "    fpr = fp / (fp + tn) if fp + tn != 0 else None\n",
    "\n",
    "    if precision < 0:\n",
    "        precision = None\n",
    "    if recall < 0:\n",
    "        recall = None\n",
    "    return accuracy, precision, recall, f1, fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNetwork(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs):\n",
    "        super(DQNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_inputs, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, n_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"re_01_ddqn.pth\"\n",
    "UPDATE_TARGET_STEPS = 200\n",
    "BATCH_SIZE = 64\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 100000\n",
    "TAU = 0.005\n",
    "LR = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNetwork(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs):\n",
    "        super(DQNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_inputs, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, n_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_actions = train_env.action_space.n\n",
    "n_inputs = train_env.observation_space.shape[0]\n",
    "\n",
    "# print(f\"n_inputs: {n_inputs}, n_actions: {n_actions}\")\n",
    "\n",
    "state = train_env.reset()\n",
    "# print(info)\n",
    "\n",
    "policy_net = DQNetwork(n_inputs, n_actions).to(device)\n",
    "target_net = DQNetwork(n_inputs, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "optimizer = optim.SGD(policy_net.parameters(), lr=LR)\n",
    "steps_done = 0\n",
    "\n",
    "memory = ReplayMemory(10000)\n",
    "episode_rewards = []\n",
    "episode_precision = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state_tensor: torch.Tensor):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * np.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            return policy_net(state_tensor).max(1).indices.view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(n_actions)]], dtype=torch.long, device=device)\n",
    "\n",
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    batch = Transaction(*zip(*transitions))\n",
    "\n",
    "    non_final_mask = torch.tensor(\n",
    "        tuple(map(lambda s: s is not None, batch.next_state)),\n",
    "        device=device,\n",
    "        dtype=torch.bool\n",
    "    )\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state if s is not None])\n",
    "\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    with torch.no_grad():\n",
    "        next_actions = policy_net(non_final_next_states).max(1).indices.unsqueeze(1)\n",
    "        next_state_values[non_final_mask] = target_net(non_final_next_states).gather(1, next_actions).squeeze(1)\n",
    "\n",
    "    expected_state_action_values = reward_batch + GAMMA * next_state_values\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    utils.clip_grad_value_(policy_net.parameters(), 1000)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "    random.seed(i_episode)\n",
    "    sum_reward = 0\n",
    "    confusion_matrix = np.zeros((2,2), dtype=int)\n",
    "\n",
    "    initial_state = train_env.reset()\n",
    "    state = torch.tensor(initial_state, device=device, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "    for t in count():\n",
    "        # select action\n",
    "        action = select_action(state)\n",
    "\n",
    "        # print(action)\n",
    "        # calculate next state\n",
    "        raw_next_state, reward, terminated, truncated, info = train_env.step(action.item())\n",
    "        row_column_index = info[\"matrix_position\"]\n",
    "        confusion_matrix[row_column_index[0], row_column_index[1]] += 1\n",
    "        # print(info)\n",
    "\n",
    "        # to tensor\n",
    "        if terminated:\n",
    "            next_state = None\n",
    "        else:\n",
    "            next_state = torch.tensor(raw_next_state, device=device, dtype=torch.float32).unsqueeze(0)\n",
    "        reward = torch.tensor([reward], device=device, dtype=torch.float32)\n",
    "\n",
    "        # store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "        sum_reward += reward.item() if reward.item() == 1 else 0\n",
    "\n",
    "        # move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # optimize the model\n",
    "        optimize_model()\n",
    "\n",
    "        if terminated:\n",
    "            episode_rewards.append(sum_reward / (t + 1))\n",
    "            break\n",
    "\n",
    "    # do after the episode\n",
    "    # episode_rewards.append(sum_reward)\n",
    "    base = confusion_matrix[1, 1] + confusion_matrix[1, 0]\n",
    "    episode_precision.append(\n",
    "        confusion_matrix[1, 1] / base if base != 0 else 0\n",
    "    )\n",
    "    # print(i_episode)\n",
    "    if i_episode > 0 and i_episode % 10 == 0:\n",
    "        plot_graph(episode_precision)\n",
    "\n",
    "# complete the episode\n",
    "plot_graph(episode_precision, show_result=True)\n",
    "torch.save(policy_net.state_dict(), MODEL_PATH)  # save the model\n",
    "\n",
    "train_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "trained_network = DQNetwork(n_inputs=n_inputs, n_outputs=n_actions).to(device)\n",
    "trained_network.load_state_dict(torch.load(MODEL_PATH, map_location=device, weights_only=True))\n",
    "trained_network.eval()\n",
    "\n",
    "# test the model\n",
    "\n",
    "confusion_array = np.zeros((2, 2), dtype=np.int32)\n",
    "metrics_dictionary = {\n",
    "    \"accuracy\": [],\n",
    "    \"precision\": [],\n",
    "    \"recall\": [],\n",
    "    \"f1\": [],\n",
    "    \"fpr\": []\n",
    "}\n",
    "\n",
    "for i_loop in range(1000):\n",
    "    random.seed(i_loop)\n",
    "    test_raw_state = test_env.reset()\n",
    "    test_state = torch.tensor(test_raw_state, device=device, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "    for t in count():\n",
    "        with torch.no_grad():\n",
    "            test_action = trained_network(test_state).max(1).indices.view(1, 1)\n",
    "\n",
    "        test_raw_next_state, test_reward, test_terminated, test_truncated, test_info = test_env.step(test_action.item())\n",
    "\n",
    "        # calculate confusion matrix\n",
    "        raw = 0 if test_reward == 1 else 1\n",
    "\n",
    "        # test_info = (row, column) means confusion matrix index\n",
    "        index = test_info[\"matrix_position\"]\n",
    "        confusion_array[index[0], index[1]] += 1\n",
    "\n",
    "        # print(index)\n",
    "\n",
    "        if test_terminated:\n",
    "            break\n",
    "\n",
    "        # make next state tensor and update state\n",
    "        test_state = torch.tensor(test_raw_next_state, device=device, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "    # calculate metrics\n",
    "    tp = confusion_array[1, 1]\n",
    "    tn = confusion_array[0, 0]\n",
    "    fp = confusion_array[1, 0]\n",
    "    fn = confusion_array[0, 1]\n",
    "    print(i_loop + 1, tp, tn, fp, fn)\n",
    "\n",
    "    accuracy, precision, recall, f1, fpr = calculate_metrics(tp, tn, fp, fn)\n",
    "    metrics_dictionary[\"accuracy\"].append(accuracy)\n",
    "    metrics_dictionary[\"precision\"].append(precision)\n",
    "    metrics_dictionary[\"recall\"].append(recall)\n",
    "    metrics_dictionary[\"f1\"].append(f1)\n",
    "    metrics_dictionary[\"fpr\"].append(fpr)\n",
    "    # print(accuracy, precision, recall, f1, fpr)\n",
    "\n",
    "\n",
    "    if i_loop % 50 == 0:\n",
    "        plot_metrics(metrics_dictionary)\n",
    "\n",
    "# plot metrics\n",
    "plot_metrics(metrics_dictionary, show_result=True)\n",
    "print(f\" accuracy: {metrics_dictionary['accuracy'][-1]}\")\n",
    "print(f\"precision: {metrics_dictionary['precision'][-1]}\")\n",
    "print(f\"  recall : {metrics_dictionary['recall'][-1]}\")\n",
    "print(f\"    f1   : {metrics_dictionary['f1'][-1]}\")\n",
    "print(f\"   fpr   : {metrics_dictionary['fpr'][-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" accuracy: {metrics_dictionary['accuracy'][-1]}\")\n",
    "print(f\"precision: {metrics_dictionary['precision'][-1]}\")\n",
    "print(f\"  recall : {metrics_dictionary['recall'][-1]}\")\n",
    "print(f\"    f1   : {metrics_dictionary['f1'][-1]}\")\n",
    "print(f\"   fpr   : {metrics_dictionary['fpr'][-1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
