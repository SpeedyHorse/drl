{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow_package.binary_flow_env import BinaryFlowEnv, InputType\n",
    "import flow_package as f_p\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from glob import glob\n",
    "import gc\n",
    "\n",
    "import matplotlib\n",
    "import random\n",
    "import json\n",
    "\n",
    "from collections import deque, namedtuple\n",
    "from itertools import count\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils as utils\n",
    "import torch.optim as optim\n",
    "\n",
    "from logging import getLogger, config\n",
    "\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "with open(\"./log_config.json\", \"r\") as f:\n",
    "    log_conf = json.load(f)\n",
    "\n",
    "config.dictConfig(log_conf)\n",
    "logger = getLogger(__name__)\n",
    "\n",
    "CONST = f_p.Const()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"=\" * 20 + \"Loading Data\" + \"=\" * 20)\n",
    "TRAIN_DIR = os.path.abspath(\"../raw_after_filtered/cicids2017/data\")\n",
    "# TRAIN_DIR = os.path.abspath(\"../raw_after_filtered/csecicids2018/data\")\n",
    "paths = glob(os.path.join(TRAIN_DIR, \"*.csv\"))\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for path in paths:\n",
    "    print(f\"\\r{path}\", end=\"\")\n",
    "    df = pd.concat([df, pd.read_csv(path, dtype=CONST.dtypes)])\n",
    "print()\n",
    "\n",
    "print(\"Data loaded\")\n",
    "logger.info(\"Data loaded\")\n",
    "df = df.dropna(how=\"any\").dropna(axis=1, how=\"any\")\n",
    "df = df.drop(columns=[\"Unnamed: 0\"]).drop_duplicates()\n",
    "\n",
    "print(\"Data cleaned\")\n",
    "logger.info(\"Data cleaned\")\n",
    "\n",
    "logger.info(\"=\" * 20 + \"Data Preprocessing\" + \"=\" * 20)\n",
    "\n",
    "_, test_data = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "TRAIN = \"../../hybrid_sample.csv\"\n",
    "path = os.path.abspath(TRAIN)\n",
    "train_data = pd.read_csv(path).drop(columns=[\"Unnamed: 0\"]).drop_duplicates()\n",
    "\n",
    "train_data[train_data[\"Number Label\"] != 0] = 1\n",
    "test_data[test_data[\"Number Label\"] != 0] = 1\n",
    "\n",
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train Normal: {len(train_data[train_data['Number Label'] == 0])}\")\n",
    "print(f\"Train Attack: {len(train_data[train_data['Number Label'] == 1])}\")\n",
    "\n",
    "logger.info(\"Over Sampling\")\n",
    "smote = SMOTE(random_state=42, sampling_strategy=\"auto\")\n",
    "x_smote, y_smote = smote.fit_resample(\n",
    "    train_data.drop(columns=[\"Number Label\"]), train_data[\"Number Label\"]\n",
    ")\n",
    "train_data = pd.concat([x_smote, y_smote], axis=1)\n",
    "print(f\"Train Normal: {len(train_data[train_data['Number Label'] == 0])}\")\n",
    "print(f\"Train Attack: {len(train_data[train_data['Number Label'] == 1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = InputType(\n",
    "    input_features=train_data.drop(columns=[\"Number Label\"]),\n",
    "    input_labels=train_data[\"Number Label\"],\n",
    "    reward_list=[1.0, -1.0],\n",
    "    type_env=None\n",
    ")\n",
    "train_env = BinaryFlowEnv(train_input)\n",
    "\n",
    "test_input = InputType(\n",
    "    input_features=test_data.drop(columns=[\"Number Label\"]),\n",
    "    input_labels=test_data[\"Number Label\"],\n",
    "    reward_list=[1.0, -1.0],\n",
    "    type_env=\"test\"\n",
    ")\n",
    "test_env = BinaryFlowEnv(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_name = \"cpu\"\n",
    "\n",
    "if True:\n",
    "    if torch.cuda.is_available():\n",
    "        device_name = \"cuda\"\n",
    "    elif torch.mps.is_available():\n",
    "        device_name = \"mps\"\n",
    "    # elif torch.hip.is_available():\n",
    "    #     device_name = \"hip\"\n",
    "    elif torch.mtia.is_available():\n",
    "        device_name = \"mtia\"\n",
    "    elif torch.xpu.is_available():\n",
    "        device_name = \"xpu\"\n",
    "\n",
    "device = torch.device(device_name)\n",
    "print(f\"device: {device_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transaction = namedtuple('Transaction', ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        # self.capacity = capacity\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        self.memory.append(Transaction(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(data, window_size):\n",
    "    weights = np.ones(window_size) / window_size\n",
    "    return np.convolve(data, weights, mode='valid')\n",
    "\n",
    "def plot_graph(data: list, show_result=False):\n",
    "    if not show_result:\n",
    "        return\n",
    "    plt.figure(figsize=(15,5))\n",
    "    # durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "\n",
    "    plt.title(\"Result\")\n",
    "    \n",
    "    \n",
    "    means = moving_average(data, 50)\n",
    "\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"ratio\")\n",
    "    plt.plot(data, color=\"lemonchiffon\")\n",
    "    plt.plot(means, color=\"red\")\n",
    "    plt.grid()\n",
    "\n",
    "    plt.savefig(\"result.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(metrics_dict: dict, show_result=False):\n",
    "    if not show_result:\n",
    "        return\n",
    "    fig = plt.figure(figsize=(16, 20))\n",
    "\n",
    "    ac = fig.add_subplot(5, 1, 1)\n",
    "    ac.plot(metrics_dict[\"accuracy\"], label=\"accuracy\")\n",
    "    ac.grid()\n",
    "    ac.set_title(\"Accuracy\")\n",
    "\n",
    "    pr = fig.add_subplot(5, 1, 2)\n",
    "    pr.plot(metrics_dict[\"precision\"], label=\"precision\", color=\"green\")\n",
    "    pr.grid()\n",
    "    pr.set_title(\"Precision\")\n",
    "\n",
    "    re = fig.add_subplot(5, 1, 3)\n",
    "    re.plot(metrics_dict[\"recall\"], label=\"recall\", color=\"red\")\n",
    "    re.grid()\n",
    "    re.set_title(\"Recall\")\n",
    "\n",
    "    f1 = fig.add_subplot(5, 1, 4)\n",
    "    f1.plot(metrics_dict[\"f1\"], label=\"f1\", color=\"black\")\n",
    "    f1.grid()\n",
    "    f1.set_title(\"F1\")\n",
    "\n",
    "    fpr = fig.add_subplot(5, 1, 5)\n",
    "    fpr.plot(metrics_dict[\"fpr\"], label=\"fpr\", color=\"purple\")\n",
    "    fpr.grid()\n",
    "    fpr.set_title(\"FPR\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(\"metrics.png\")\n",
    "\n",
    "\n",
    "def calculate_metrics(tp, tn, fp, fn):\n",
    "    accuracy = (tp + tn) / (tp + fp + fn + tn)\n",
    "    precision = tp / (tp + fp) if tp + fp != 0 else -1\n",
    "    recall = tp / (tp + fn) if tp + fn != 0 else -1\n",
    "    f1 = 2 * precision * recall / (precision + recall) if precision + recall != 0 else None\n",
    "    fpr = fp / (fp + tn) if fp + tn != 0 else None\n",
    "\n",
    "    if precision < 0:\n",
    "        precision = None\n",
    "    if recall < 0:\n",
    "        recall = None\n",
    "    return accuracy, precision, recall, f1, fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PORT_DIM = 32\n",
    "class DeepFlowNetwork(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs):\n",
    "        super(DeepFlowNetwork, self).__init__()\n",
    "\n",
    "        self.protocol_embedding = nn.Embedding(256, 8) # -> 8\n",
    "        self.port_embedding = nn.Embedding(65536, PORT_DIM) # -> 8\n",
    "        # other inputs are not embedding: n_inputs - 2\n",
    "\n",
    "        # all inputs: n_inputs - 2 + 8 + 8 = n_inputs + 14\n",
    "        n_inputs = n_inputs + 6 + PORT_DIM\n",
    "\n",
    "        self.fc1 = nn.Linear(n_inputs, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc3 = nn.Linear(256, n_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        port_emb = self.port_embedding(x[0].long())\n",
    "        protocol_emb = self.protocol_embedding(x[1].long())\n",
    "\n",
    "        # print(port_emb.shape, protocol_emb.shape, x[2].shape)\n",
    "\n",
    "        renew = torch.cat([port_emb, protocol_emb, x[2]], dim=1)\n",
    "\n",
    "        renew = F.relu(self.fc1(renew))\n",
    "        renew = F.relu(self.fc2(renew))\n",
    "        return self.fc3(renew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UPDATE_TARGET_STEPS = 200\n",
    "BATCH_SIZE = 64\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 100000\n",
    "TAU = 0.005\n",
    "LR = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"=\" * 20 + \"Training\" + \"=\" * 20)\n",
    "logger.info(\"set variables\")\n",
    "n_actions = train_env.action_space.n\n",
    "n_inputs = train_env.observation_space.shape[0]\n",
    "\n",
    "# print(f\"n_inputs: {n_inputs}, n_actions: {n_actions}\")\n",
    "\n",
    "state = train_env.reset()\n",
    "# print(info)\n",
    "\n",
    "policy_net = DeepFlowNetwork(n_inputs, n_actions).to(device)\n",
    "target_net = DeepFlowNetwork(n_inputs, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "optimizer = optim.SGD(policy_net.parameters(), lr=LR)\n",
    "steps_done = 0\n",
    "\n",
    "memory = ReplayMemory(10000)\n",
    "episode_rewards = []\n",
    "episode_precision = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state_tensor: torch.Tensor):\n",
    "    # print(f\"state_tensor: {state_tensor[0,1]}\")\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * np.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # print(policy_net(state_tensor))\n",
    "            # print(policy_net(state_tensor).max(1))\n",
    "            return policy_net(state_tensor).max(1).indices.view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(n_actions)]], dtype=torch.long, device=device)\n",
    "\n",
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    batch = Transaction(*zip(*transitions))\n",
    "\n",
    "    non_final_mask = torch.tensor(\n",
    "        tuple(map(lambda s: s is not None, batch.next_state)),\n",
    "        device=device,\n",
    "        dtype=torch.bool\n",
    "    )\n",
    "    # non_final_next_states = torch.cat([s for s in batch.next_state if s is not None])\n",
    "\n",
    "    # print(batch.state[0])\n",
    "    state_batch_port = torch.cat([s[0] for s in batch.state])\n",
    "    state_batch_protocol = torch.cat([s[1] for s in batch.state])\n",
    "    state_batch_other = torch.cat([s[2] for s in batch.state])\n",
    "\n",
    "    state_batch = [state_batch_port, state_batch_protocol, state_batch_other]\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    # non_final_next_states も同様に処理\n",
    "    non_final_next_states_port = torch.cat([s[0] for s in batch.next_state if s is not None])\n",
    "    non_final_next_states_protocol = torch.cat([s[1] for s in batch.next_state if s is not None])\n",
    "    non_final_next_states_features = torch.cat([s[2] for s in batch.next_state if s is not None])\n",
    "    non_final_next_states = [non_final_next_states_port, non_final_next_states_protocol, non_final_next_states_features]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1).values\n",
    "\n",
    "    expected_state_action_values = reward_batch + GAMMA * next_state_values\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    utils.clip_grad_value_(policy_net.parameters(), 1000)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Training start\")\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "    random.seed(i_episode)\n",
    "    sum_reward = 0\n",
    "    confusion_matrix = np.zeros((2,2), dtype=int)\n",
    "\n",
    "    initial_state = train_env.reset()\n",
    "    # state = torch.tensor(initial_state, device=device, dtype=torch.float32).unsqueeze(0)\n",
    "    state = f_p.to_tensor(initial_state, device)\n",
    "\n",
    "    for t in count():\n",
    "        # select action\n",
    "        action = select_action(state)\n",
    "\n",
    "        # print(action)\n",
    "        # calculate next state\n",
    "        raw_next_state, reward, terminated, truncated, info = train_env.step(action.item())\n",
    "        row_column_index = info[\"matrix_position\"]\n",
    "        # print(info)\n",
    "        confusion_matrix[row_column_index[0], row_column_index[1]] += 1\n",
    "        # print(info)\n",
    "\n",
    "        # to tensor\n",
    "        if terminated:\n",
    "            next_state = None\n",
    "        else:\n",
    "            # next_state = torch.tensor(raw_next_state, device=device, dtype=torch.float32).unsqueeze(0)\n",
    "            next_state = f_p.to_tensor(raw_next_state, device)\n",
    "        reward = torch.tensor([reward], device=device, dtype=torch.float32)\n",
    "\n",
    "        # store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "        sum_reward += reward.item() if reward.item() == 1 else 0\n",
    "\n",
    "        # move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # optimize the model\n",
    "        # print(\"optimize_model\")\n",
    "        optimize_model()\n",
    "\n",
    "        if terminated:\n",
    "            episode_rewards.append(sum_reward / (t + 1))\n",
    "            break\n",
    "\n",
    "    # do after the episode\n",
    "    # episode_rewards.append(sum_reward)\n",
    "    base = confusion_matrix[1, 1] + confusion_matrix[1, 0]\n",
    "    episode_precision.append(\n",
    "        confusion_matrix[1, 1] / base if base != 0 else 0\n",
    "    )\n",
    "    logger.info(\n",
    "        f\"Episode {i_episode} finished after {t + 1} steps. \"\n",
    "        f\"Reward: {sum_reward}, Precision: {episode_precision[-1]}\"\n",
    "    )\n",
    "    \n",
    "    if i_episode > 0 and i_episode % 10 == 0:\n",
    "        plot_graph(episode_precision)\n",
    "\n",
    "# complete the episode\n",
    "plot_graph(episode_precision, show_result=True)\n",
    "torch.save(policy_net.state_dict(), \"re_01_dqn_cic.pth\")  # save the model\n",
    "\n",
    "train_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"=\" * 20 + \"Testing\" + \"=\" * 20)\n",
    "MODEL_PATH = \"re_01_dqn_cic.pth\"\n",
    "\n",
    "# load the model\n",
    "trained_network = DeepFlowNetwork(n_inputs=n_inputs, n_outputs=n_actions).to(device)\n",
    "trained_network.load_state_dict(torch.load(MODEL_PATH, map_location=device, weights_only=True))\n",
    "trained_network.eval()\n",
    "\n",
    "# test the model\n",
    "\n",
    "confusion_array = np.zeros((2, 2), dtype=np.int32)\n",
    "metrics_dictionary = {\n",
    "    \"accuracy\": [],\n",
    "    \"precision\": [],\n",
    "    \"recall\": [],\n",
    "    \"f1\": [],\n",
    "    \"fpr\": []\n",
    "}\n",
    "\n",
    "logger.info(\"Testing start\")\n",
    "for i_loop in range(10):\n",
    "    random.seed(i_loop)\n",
    "    test_raw_state = test_env.reset()\n",
    "    try:\n",
    "        test_state = f_p.to_tensor(test_raw_state, device)\n",
    "    except:\n",
    "        raise print(test_raw_state)\n",
    "    for t in count():\n",
    "        with torch.no_grad():\n",
    "            test_action = trained_network(test_state).max(1).indices.view(1, 1)\n",
    "\n",
    "        test_raw_next_state, test_reward, test_terminated, test_truncated, test_info = test_env.step(test_action.item())\n",
    "        # print(test_info)\n",
    "        # calculate confusion matrix\n",
    "        raw = 0 if test_reward == 1 else 1\n",
    "\n",
    "        # test_info = (row, column) means confusion matrix index\n",
    "        index = test_info[\"matrix_position\"]\n",
    "        confusion_array[index[0], index[1]] += 1\n",
    "\n",
    "        # print(index)\n",
    "\n",
    "        if test_terminated:\n",
    "            break\n",
    "\n",
    "        # make next state tensor and update state\n",
    "        #test_state = torch.tensor(test_raw_next_state, device=device, dtype=torch.float32).unsqueeze(0)\n",
    "        test_state = f_p.to_tensor(test_raw_next_state, device)\n",
    "\n",
    "    # calculate metrics\n",
    "    tp = confusion_array[1, 1]\n",
    "    tn = confusion_array[0, 0]\n",
    "    fp = confusion_array[1, 0]\n",
    "    fn = confusion_array[0, 1]\n",
    "    print(f\"{i_loop + 1:5}, {tp:7}, {tn:7}, {fp:7}, {fn:7}\")\n",
    "    logger.info(\n",
    "        f\"{i_loop + 1:5}, {tp:7}, {tn:7}, {fp:7}, {fn:7}\"\n",
    "    )\n",
    "\n",
    "    accuracy, precision, recall, f1, fpr = calculate_metrics(tp, tn, fp, fn)\n",
    "    metrics_dictionary[\"accuracy\"].append(accuracy)\n",
    "    metrics_dictionary[\"precision\"].append(precision)\n",
    "    metrics_dictionary[\"recall\"].append(recall)\n",
    "    metrics_dictionary[\"f1\"].append(f1)\n",
    "    metrics_dictionary[\"fpr\"].append(fpr)\n",
    "    # print(accuracy, precision, recall, f1, fpr)\n",
    "\n",
    "# plot metrics\n",
    "plot_metrics(metrics_dictionary, show_result=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
